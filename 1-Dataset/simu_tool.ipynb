{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1.Get simulation list of leak data'''\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "path='D:\\\\0-Data\\\\9-stcleak3\\\\'\n",
    "if not os.path.exists(path+'cons\\\\'):\n",
    "    os.makedirs(path+'cons\\\\')\n",
    "#Prepare the node and pipeline files first\n",
    "encoding='utf-8'\n",
    "unit=pd.read_csv(path+'netcsv\\\\1.PipeData.csv',encoding=encoding)#pipeline\n",
    "base_user_flow=np.array(pd.read_csv(path+'netcsv\\\\6.SinkData.csv',usecols=[6],encoding=encoding)).T#scenarios\n",
    "#Get the simulation list\n",
    "n=5#sample quantity multiplier\n",
    "error=0.1#scenario change rate\n",
    "error_name='0100'\n",
    "for i in tqdm(range(len(unit))):#for each pipeline\n",
    "    L=unit.loc[i,'长度']\n",
    "    num=(int(math.log(L))+1)*n#n samples for every meter\n",
    "    loc_ratio=np.round(np.random.uniform(low=0.005,high=0.995,size=[num,1]),3)#leak location ratio\n",
    "    loc=np.round(loc_ratio*L,4)#leak location, m\n",
    "    user_flow=base_user_flow*np.random.uniform(low=1-error,high=1+error,size=[num,len(base_user_flow[0])])#various scenarios\n",
    "    cycle_flow=np.sum(user_flow,axis=1).reshape([-1,1])\n",
    "    leak_size=np.random.uniform(low=np.sum(base_user_flow)*0.001,high=np.sum(base_user_flow)*0.01,size=[num,1])#leak flow, kg/s\n",
    "    leak_ratio=np.round(leak_size/cycle_flow,3)#leak ratio\n",
    "    simu_index=np.array(list(range(num))).reshape([-1,1])\n",
    "    t=np.hstack([simu_index,loc,loc_ratio,leak_size,leak_ratio,cycle_flow,user_flow])\n",
    "    t=pd.DataFrame(t)\n",
    "    t.columns=['SimuIndex','Loc','LocRatio','Leak','LeakRatio','TotalFlow']+['UserFlow_'+str(i+1) for i in range(len(base_user_flow[0]))]\n",
    "\n",
    "    t['Code']=unit.loc[i,'编号'].astype(int)\n",
    "    t['ID']=unit.loc[i,'名称']\n",
    "    t['Fault']='pipeLeak'\n",
    "    t['Loc']=t['Loc'].astype(float)\n",
    "    t['SimuIndex']=t['SimuIndex'].astype(int)\n",
    "    t=t[['SimuIndex','Fault','Code','ID','Loc','LocRatio','Leak','LeakRatio','TotalFlow']+['UserFlow_'+str(i+1) for i in range(len(base_user_flow[0]))]]\n",
    "    t.to_csv(path+'cons\\\\constraint_'+error_name+'_'+str(i)+'_leak.csv',index=False)#leak scenarios\n",
    "    t['Leak']=0\n",
    "    t['LeakRatio']=0\n",
    "    t.to_csv(path+'cons\\\\constraint_'+error_name+'_'+str(i)+'_noleak.csv',index=False)#normal scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''2.Leak data simulation'''\n",
    "# See json_tool.py & leak_simu_json.py\n",
    "# Run leak_simu_json.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3.Collect leak data'''\n",
    "import time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main(i,error,leak):\n",
    "    main_path='E:\\\\0-Work\\\\Data\\\\9-stcleak3\\\\'\n",
    "    info=pd.read_csv(main_path+'cons\\\\constraint_'+error+'_'+str(i)+'_'+leak+'.csv',header=0)\n",
    "    source_name='0.SourceDataResult.csv'\n",
    "    pipe_name='1.PipeDataResult.csv'\n",
    "    twoway_name='2.TwowaysDataResult.csv'\n",
    "    tee_name='3.TeesDataResult.csv'\n",
    "    cross_name='4.CrossDataResult.csv'\n",
    "    plug_name='5.PlugDataResult.csv'\n",
    "    sink_name='6.SinkDataResult.csv'\n",
    "    valve_name='7.ValveDataResult.csv'\n",
    "\n",
    "    col=pd.DataFrame()\n",
    "    L=len(info)\n",
    "    for j in tqdm(range(L)):\n",
    "        path=main_path+'result_'+leak+'\\\\'+error+'\\\\pipe_'+str(i)+'\\\\'+str(j)+'\\\\'\n",
    "        try:\n",
    "            source_p=pd.read_csv(path+source_name,header=0,usecols=[2]).T.reset_index(drop=True)#2\n",
    "            source_m=pd.read_csv(path+source_name,header=0,usecols=[4]).T.reset_index(drop=True)#2\n",
    "            sink_p=pd.read_csv(path+sink_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            sink_m=pd.read_csv(path+sink_name,header=0,usecols=[4]).T.reset_index(drop=True)\n",
    "            pipe_p1=pd.read_csv(path+pipe_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            pipe_p2=pd.read_csv(path+pipe_name,header=0,usecols=[5]).T.reset_index(drop=True)\n",
    "            pipe_m=pd.read_csv(path+pipe_name,header=0,usecols=[9]).T.reset_index(drop=True)\n",
    "            two_p=pd.read_csv(path+twoway_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            two_m=pd.read_csv(path+twoway_name,header=0,usecols=[5]).T.reset_index(drop=True)\n",
    "            tee_p=pd.read_csv(path+tee_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            tee_m=pd.read_csv(path+tee_name,header=0,usecols=[5]).T.reset_index(drop=True)\n",
    "            cross_p=pd.read_csv(path+cross_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            cross_m=pd.read_csv(path+cross_name,header=0,usecols=[5]).T.reset_index(drop=True)\n",
    "            plug_p=pd.read_csv(path+plug_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            valve_p1=pd.read_csv(path+valve_name,header=0,usecols=[2]).T.reset_index(drop=True)\n",
    "            valve_p2=pd.read_csv(path+valve_name,header=0,usecols=[5]).T.reset_index(drop=True)\n",
    "            valve_m=pd.read_csv(path+valve_name,header=0,usecols=[3]).T.reset_index(drop=True)\n",
    "    \n",
    "            cat=pd.concat([source_m,source_p,sink_p,sink_m,two_p,tee_p,cross_p,valve_p1,valve_p2,valve_m,two_m,tee_m,cross_m,plug_p,pipe_p1,pipe_p2,pipe_m],axis=1) #horizontal\n",
    "            cat.columns=[i for i in range(4577)]\n",
    "            col=pd.concat([col,cat],axis=0) #vertical\n",
    "        except Exception as e:\n",
    "            if j!=0:\n",
    "                col=pd.concat([col,pd.DataFrame([''])],axis=0)\n",
    "            elif j==0:\n",
    "                temp=pd.DataFrame([[np.nan for i in range(4577)]])\n",
    "                col=pd.concat([col,temp],axis=0)\n",
    "\n",
    "    col=col.reset_index(drop=True)\n",
    "    col=pd.concat([info,col],axis=1)#horizontal\n",
    "    # dimension of each part\n",
    "    source_num,sink_num,pipe_num,two_num,tee_num,cross_num,plug_num,valve_num=source_p.shape[1],sink_p.shape[1],pipe_p1.shape[1],two_p.shape[1],tee_p.shape[1],cross_p.shape[1],plug_p.shape[1],valve_p1.shape[1]\n",
    "    # rename\n",
    "    Source=[str(i+1)+'_SourceM' for i in range(source_num)]+[str(i+1)+'_SourceP' for i in range(source_num)]# water source\n",
    "    Sink=[str(i+1)+'_SinkP' for i in range(sink_num)]+[str(i+1)+'_SinkM' for i in range(sink_num)]# water user\n",
    "    TwoP,TwoM=[str(i+1)+'_2P' for i in range(two_num)],[str(i+1)+'_2M' for i in range(two_num)]# twoway\n",
    "    TeeP,TeeM=[str(i+1)+'_3P' for i in range(tee_num)],[str(i+1)+'_3M' for i in range(tee_num)]# tee-joint\n",
    "    CrossP,CrossM=[str(i+1)+'_4P' for i in range(cross_num)],[str(i+1)+'_4M' for i in range(cross_num)]# cross\n",
    "    Plug=[str(i+1)+'_PlugP' for i in range(plug_num)]# plug\n",
    "    Valve=[str(i+1)+'_ValveP1' for i in range(valve_num)]+[str(i+1)+'_ValveP2' for i in range(valve_num)]+[str(i+1)+'_ValveM' for i in range(valve_num)]# valve\n",
    "    Pipe=[str(i+1)+'_PipeP1' for i in range(pipe_num)]+[str(i+1)+'_PipeP2' for i in range(pipe_num)]+[str(i+1)+'_PM' for i in range(pipe_num)]# pipeline\n",
    "\n",
    "    Label=['SimuIndex','Fault','Code','ID','Loc','LocRatio','Leak','LeakRatio','TotalFlow']+['UserFlow_'+str(i+1) for i in range(sink_num)]\n",
    "    col.columns=Label+Source+Sink+TwoP+TeeP+CrossP+Valve+TwoM+TeeM+CrossM+Plug+Pipe\n",
    "\n",
    "    col.to_csv(main_path+'\\\\result_'+leak+'\\\\'+error+'\\\\sample_'+error+'_pipe_'+str(i)+'_'+leak+'.csv',index=False)\n",
    "\n",
    "time1=time.time()\n",
    "name_list=['0100']\n",
    "for j in range(len(name_list)):\n",
    "    error_name=name_list[j]\n",
    "    for i in range(0,603):\n",
    "        print('error',error_name,'pipe:',i)\n",
    "        main(i,error_name,'leak')#leak noleak\n",
    "time2=time.time()\n",
    "print('all done in:',round(time2-time1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''4.Get residual data'''\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def main(i,error):\n",
    "    main_path='D:\\\\0-Data\\\\9-stcleak4\\\\'\n",
    "    if not os.path.exists(main_path+'dataset\\\\'):\n",
    "        os.makedirs(main_path+'dataset\\\\') \n",
    "    if not os.path.exists(main_path+'dataset\\\\'+error+'\\\\'):\n",
    "        os.makedirs(main_path+'dataset\\\\'+error+'\\\\')    \n",
    "    leak='noleak'\n",
    "    info_0=pd.read_csv(main_path+'result_'+leak+'\\\\'+error+'\\\\sample_'+error+'_pipe_'+str(i)+'_'+leak+'.csv',header=0)\n",
    "    leak='leak'\n",
    "    info_1=pd.read_csv(main_path+'result_'+leak+'\\\\'+error+'\\\\sample_'+error+'_pipe_'+str(i)+'_'+leak+'.csv',header=0)\n",
    "    residual=info_1.copy()\n",
    "    residual.iloc[:,117:]=info_1.iloc[:,117:]-info_0.iloc[:,117:]\n",
    "    residual.iloc[:,[117,118]+list(range(229,337))]=info_1.iloc[:,[117,118]+list(range(229,337))]#origin data of flow\n",
    "\n",
    "    residual.to_csv(main_path+'dataset\\\\'+error+'\\\\sample_'+error+'_pipe_'+str(i)+'_residual.csv',index=False)\n",
    "\n",
    "name_list=['0100']\n",
    "for j in range(len(name_list)):\n",
    "    error_name=name_list[j]\n",
    "    for i in tqdm(range(603)):\n",
    "        main(i,error_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''5.Add features of pressures of calibration points '''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path='D:\\\\0-Data\\\\9-stcleak4\\\\'\n",
    "encoding='utf-8'#'GBK'\n",
    "source=pd.read_csv(path+'netcsv\\\\0.SourceData.csv',header=0,encoding=encoding)\n",
    "source1=source.copy()\n",
    "source1['attr']='source'\n",
    "pipe=pd.read_csv(path+'netcsv\\\\1.PipeData.csv',header=0,encoding=encoding)\n",
    "pipe1=pipe.copy()\n",
    "pipe1['attr']='pipe'\n",
    "two=pd.read_csv(path+'netcsv\\\\2.TwowaysData.csv',header=0,encoding=encoding)\n",
    "two1=two.copy()\n",
    "two1['attr']='two'\n",
    "tee=pd.read_csv(path+'netcsv\\\\3.TeesData.csv',header=0,encoding=encoding)\n",
    "tee1=tee.copy()\n",
    "tee1['attr']='tee'\n",
    "cross=pd.read_csv(path+'netcsv\\\\4.CrossData.csv',header=0,encoding=encoding)\n",
    "cross1=cross.copy()\n",
    "cross1['attr']='cross'\n",
    "plug=pd.read_csv(path+'netcsv\\\\5.PlugData.csv',header=0,encoding=encoding)\n",
    "plug1=plug.copy()\n",
    "plug1['attr']='plug'\n",
    "sink=pd.read_csv(path+'netcsv\\\\6.SinkData.csv',header=0,encoding=encoding)\n",
    "sink1=sink.copy()\n",
    "sink1['attr']='sink'\n",
    "valve=pd.read_csv(path+'netcsv\\\\7.ValveData.csv',header=0,encoding=encoding)\n",
    "valve1=valve.copy()\n",
    "valve1['attr']='valve'\n",
    "#files with 1 for searching, origin files for modifying\n",
    "nodes=pd.concat([source1,sink1,valve1,plug1,two1,tee1,cross1],axis=0).reset_index(drop=True)\n",
    "files={'source':source,'pipe':pipe,'two':two,'tee':tee,'cross':cross,'plug':plug,'sink':sink,'valve':valve}\n",
    "column_name={'two':'_2P','tee':'_3P','plug':'_PlugP','valve1':'_ValveP1','valve2':'_ValveP2'}\n",
    "\n",
    "cali_info=pd.read_excel(path+'netcsv\\\\calipoint.xlsx')#from project data\n",
    "pipe_info=pd.read_excel(path+'netcsv\\\\pipeinfo.xlsx')#from project data\n",
    "data_info=pd.read_csv(path+'result_leak\\\\0100\\\\sample_0100_pipe_0_leak.csv')\n",
    "\n",
    "get_info=[]\n",
    "column_index=[]\n",
    "for i in range(len(cali_info)):\n",
    "    gis_code=cali_info.loc[i,'管线编号']\n",
    "    pipe_index=np.where(pipe_info['GIS编号']==gis_code)[0][0]\n",
    "    pipe_code=pipe_info.loc[pipe_index,'管道编号']\n",
    "    pipe_index2=np.where(pipe['名称']==pipe_code)[0][0]\n",
    "    node1_code=pipe.loc[pipe_index2,'口1连接元件编号']\n",
    "    node1_index=np.where(nodes['编号']==node1_code)[0][0]\n",
    "    node1_attr=nodes.loc[node1_index,'attr']\n",
    "    node1_index2=np.where(files[node1_attr]['编号']==node1_code)[0][0]\n",
    "    if node1_attr=='valve':\n",
    "        node1_kou=np.where(pipe_index2==valve[['口1连接元件编号','口2连接元件编号']])[1][0]+1\n",
    "        node1_column_index=np.where(data_info.columns==(str(node1_index2+1)+column_name[node1_attr+str(node1_kou)]))[0][0]\n",
    "    else:\n",
    "        node1_column_index=np.where(data_info.columns==(str(node1_index2+1)+column_name[node1_attr]))[0][0]\n",
    "\n",
    "    node2_code=pipe.loc[pipe_index2,'口2连接元件编号']\n",
    "    node2_index=np.where(nodes['编号']==node2_code)[0][0]\n",
    "    node2_attr=nodes.loc[node2_index,'attr']\n",
    "    node2_index2=np.where(files[node2_attr]['编号']==node2_code)[0][0]\n",
    "    if node2_attr=='valve':\n",
    "        node2_kou=np.where(pipe_index2==valve[['口1连接元件编号','口2连接元件编号']])[1][0]+1\n",
    "        node2_column_index=np.where(data_info.columns==(str(node2_index2+1)+column_name[node2_attr+str(node2_kou)]))[0][0]\n",
    "    else:\n",
    "        node2_column_index=np.where(data_info.columns==(str(node2_index2+1)+column_name[node2_attr]))[0][0]\n",
    "\n",
    "    get_info.append([node1_code,node1_attr,node1_index2,node1_column_index,\n",
    "                     node2_code,node2_attr,node2_index2,node2_column_index])\n",
    "    \n",
    "new_info=pd.DataFrame(get_info)\n",
    "new_info.columns=['口1连接元件编号','口1连接元件类型','口1连接元件序号','口1连接元件列号','口2连接元件编号','口2连接元件类型','口2连接元件序号','口2连接元件列号']\n",
    "cali_info1=pd.concat([cali_info,new_info],axis=1)\n",
    "cali_info1.to_csv(path+'netcsv\\\\cali_info.csv',index=False,encoding='GBK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6.Extract features we need'''\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "path='D:\\\\0-Data\\\\9-stcleak4\\\\'\n",
    "error='0100'\n",
    "out_path=path+'dataset\\\\'+error+'\\\\feature\\\\'\n",
    "if not os.path.exists(out_path):\n",
    "    os.makedirs(out_path) \n",
    "# feature index\n",
    "info_i=list(range(9))\n",
    "source_m=[117,118]\n",
    "source_p=[119,120]\n",
    "user_p=list(range(121,229))\n",
    "user_m=list(range(229,337))\n",
    "\n",
    "# calibration index\n",
    "cali_info1=pd.read_csv(path+'netcsv\\\\cali_info.csv',encoding='GBK')\n",
    "column_index_list=[]\n",
    "for i in range(len(cali_info1)):\n",
    "    kou1_attr,kou2_attr=cali_info1.loc[i,'口1连接元件类型'],cali_info1.loc[i,'口2连接元件类型']\n",
    "    if kou1_attr=='valve':\n",
    "        column_index_list.append(cali_info1.loc[i,'口1连接元件列号'])\n",
    "    elif kou1_attr!='plug':\n",
    "        if kou2_attr=='plug':\n",
    "            column_index_list.append(cali_info1.loc[i,'口1连接元件列号'])\n",
    "        elif kou2_attr=='valve':\n",
    "            column_index_list.append(cali_info1.loc[i,'口2连接元件列号'])\n",
    "calib_p=np.sort(column_index_list).tolist()\n",
    "\n",
    "feature_index=info_i+source_m+source_p+user_p+user_m+calib_p\n",
    "for i in tqdm(range(603)):\n",
    "    origin_dataset=pd.read_csv(path+'dataset\\\\'+error+'\\\\sample_'+error+'_pipe_'+str(i)+'_residual.csv',header=0).dropna()\n",
    "    simple_dataset=origin_dataset.iloc[:,feature_index]\n",
    "    simple_dataset.to_csv(out_path+'sample_'+error+'_pipe_'+str(i)+'_residual_feature.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
